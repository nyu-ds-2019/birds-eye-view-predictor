{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "from modules.parts_top_view_AE import Autoencoder\n",
    "from modules.encodings_dataset import EncodingsDataset\n",
    "from modules.module_utils import Flatten\n",
    "from modules.module_utils import DeFlatten\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(512, 64)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "workers = 2\n",
    "\n",
    "train_dataset = EncodingsDataset(\n",
    "    '../artifacts',\n",
    "    'ae_latent_noise_gpu_model_b64_w2_e10.pt',\n",
    "    'front_right',\n",
    "    'train',\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225],\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = EncodingsDataset(\n",
    "    '../artifacts',\n",
    "    'ae_latent_noise_gpu_model_b64_w2_e10.pt',\n",
    "    'front_right',\n",
    "    'val',\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True, sampler=None)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size, shuffle=True,\n",
    "    num_workers=workers, pin_memory=True)\n",
    "\n",
    "learning_rate = 1e-1\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- running epoch 1 --\n",
      "epoch [1/50], data trained:3.154%, running avg training loss:1921.9427\n",
      "-- running epoch 2 --\n",
      "epoch [2/50], data trained:3.154%, running avg training loss:1705.7324\n",
      "-- running epoch 3 --\n",
      "epoch [3/50], data trained:3.154%, running avg training loss:1614.0417\n",
      "-- running epoch 4 --\n",
      "epoch [4/50], data trained:3.154%, running avg training loss:1512.3309\n",
      "-- running epoch 5 --\n",
      "epoch [5/50], data trained:3.154%, running avg training loss:1392.5255\n",
      "-- running epoch 6 --\n",
      "epoch [6/50], data trained:3.154%, running avg training loss:1296.4574\n",
      "-- running epoch 7 --\n",
      "epoch [7/50], data trained:3.154%, running avg training loss:1192.3247\n",
      "-- running epoch 8 --\n",
      "epoch [8/50], data trained:3.154%, running avg training loss:1056.6364\n",
      "-- running epoch 9 --\n",
      "epoch [9/50], data trained:3.154%, running avg training loss:961.8998\n",
      "-- running epoch 10 --\n",
      "epoch [10/50], data trained:3.154%, running avg training loss:874.3258\n",
      "-- running epoch 11 --\n",
      "epoch [11/50], data trained:3.154%, running avg training loss:776.2468\n",
      "-- running epoch 12 --\n",
      "epoch [12/50], data trained:3.154%, running avg training loss:678.3845\n",
      "-- running epoch 13 --\n",
      "epoch [13/50], data trained:3.154%, running avg training loss:591.6873\n",
      "-- running epoch 14 --\n",
      "epoch [14/50], data trained:3.154%, running avg training loss:531.2360\n",
      "-- running epoch 15 --\n",
      "epoch [15/50], data trained:3.154%, running avg training loss:463.5798\n",
      "-- running epoch 16 --\n",
      "epoch [16/50], data trained:3.154%, running avg training loss:401.4727\n",
      "-- running epoch 17 --\n",
      "epoch [17/50], data trained:3.154%, running avg training loss:341.9238\n",
      "-- running epoch 18 --\n",
      "epoch [18/50], data trained:3.154%, running avg training loss:302.1441\n",
      "-- running epoch 19 --\n",
      "epoch [19/50], data trained:3.154%, running avg training loss:252.4568\n",
      "-- running epoch 20 --\n",
      "epoch [20/50], data trained:3.154%, running avg training loss:232.6080\n",
      "-- running epoch 21 --\n",
      "epoch [21/50], data trained:3.154%, running avg training loss:205.0408\n",
      "-- running epoch 22 --\n",
      "epoch [22/50], data trained:3.154%, running avg training loss:185.8726\n",
      "-- running epoch 23 --\n",
      "epoch [23/50], data trained:3.154%, running avg training loss:168.2530\n",
      "-- running epoch 24 --\n",
      "epoch [24/50], data trained:3.154%, running avg training loss:157.4862\n",
      "-- running epoch 25 --\n",
      "epoch [25/50], data trained:3.154%, running avg training loss:151.7701\n",
      "-- running epoch 26 --\n",
      "epoch [26/50], data trained:3.154%, running avg training loss:139.2066\n",
      "-- running epoch 27 --\n",
      "epoch [27/50], data trained:3.154%, running avg training loss:127.7907\n",
      "-- running epoch 28 --\n",
      "epoch [28/50], data trained:3.154%, running avg training loss:121.6164\n",
      "-- running epoch 29 --\n",
      "epoch [29/50], data trained:3.154%, running avg training loss:124.2592\n",
      "-- running epoch 30 --\n",
      "epoch [30/50], data trained:3.154%, running avg training loss:115.6078\n",
      "-- running epoch 31 --\n",
      "epoch [31/50], data trained:3.154%, running avg training loss:99.6496\n",
      "-- running epoch 32 --\n",
      "epoch [32/50], data trained:3.154%, running avg training loss:94.3216\n",
      "-- running epoch 33 --\n",
      "epoch [33/50], data trained:3.154%, running avg training loss:91.8885\n",
      "-- running epoch 34 --\n",
      "epoch [34/50], data trained:3.154%, running avg training loss:89.1431\n",
      "-- running epoch 35 --\n",
      "epoch [35/50], data trained:3.154%, running avg training loss:91.9345\n",
      "-- running epoch 36 --\n",
      "epoch [36/50], data trained:3.154%, running avg training loss:83.6073\n",
      "-- running epoch 37 --\n",
      "epoch [37/50], data trained:3.154%, running avg training loss:79.4878\n",
      "-- running epoch 38 --\n",
      "epoch [38/50], data trained:3.154%, running avg training loss:84.1946\n",
      "-- running epoch 39 --\n",
      "epoch [39/50], data trained:3.154%, running avg training loss:82.3268\n",
      "-- running epoch 40 --\n",
      "epoch [40/50], data trained:3.154%, running avg training loss:72.6509\n",
      "-- running epoch 41 --\n",
      "epoch [41/50], data trained:3.154%, running avg training loss:70.9959\n",
      "-- running epoch 42 --\n",
      "epoch [42/50], data trained:3.154%, running avg training loss:80.0574\n",
      "-- running epoch 43 --\n",
      "epoch [43/50], data trained:3.154%, running avg training loss:73.1676\n",
      "-- running epoch 44 --\n",
      "epoch [44/50], data trained:3.154%, running avg training loss:71.6612\n",
      "-- running epoch 45 --\n",
      "epoch [45/50], data trained:3.154%, running avg training loss:76.5873\n",
      "-- running epoch 46 --\n",
      "epoch [46/50], data trained:3.154%, running avg training loss:70.8002\n",
      "-- running epoch 47 --\n",
      "epoch [47/50], data trained:3.154%, running avg training loss:64.3376\n",
      "-- running epoch 48 --\n",
      "epoch [48/50], data trained:3.154%, running avg training loss:60.4192\n",
      "-- running epoch 49 --\n",
      "epoch [49/50], data trained:3.154%, running avg training loss:56.3731\n",
      "-- running epoch 50 --\n",
      "epoch [50/50], data trained:3.154%, running avg training loss:53.4421\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "dataset_len = len(train_loader.dataset)\n",
    "val_dataset_len = len(val_loader.dataset)\n",
    "validation_losses = []\n",
    "running_avg_training_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    total = 0\n",
    "    running_total_training_loss = 0\n",
    "\n",
    "    print(f'-- running epoch {epoch + 1} --')\n",
    "\n",
    "    for data in train_loader:\n",
    "        img, expected_output = data\n",
    "        img = img.to(device)\n",
    "        expected_output = expected_output.to(device)\n",
    "        expected_output = expected_output.view(expected_output.shape[0], expected_output.shape[2])\n",
    "        # ===================forward=====================\n",
    "        output = model(img) \n",
    "        loss = criterion(output, expected_output)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += 1    \n",
    "\n",
    "        running_total_training_loss += float(loss)    \n",
    "#         if len(validation_losses) == 0:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}')\n",
    "#         else:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}, validation loss (prev epoch):{validation_losses[-1]}')\n",
    "    \n",
    "    running_avg_training_losses.append(running_total_training_loss/total)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         total_vloss = 0\n",
    "#         for val_data in val_loader:\n",
    "#             vimg, v_expected_output = val_data\n",
    "#             vimg = vimg.to(device)\n",
    "#             voutput = model(vimg)\n",
    "#             vloss = criterion(voutput, v_expected_output)\n",
    "#             total_vloss += vloss\n",
    "#         validation_losses.append(total_vloss)\n",
    "\n",
    "\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, running avg training loss:{running_avg_training_losses[-1]:.4f}')\n",
    "#     print(validation_losses)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.save(model, '../artifacts/models/street_cnn_front_right_gpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(torch.device('cpu'))\n",
    "            torch.save(model, '../artifacts/models/street_cnn_front_right_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(device)   \n",
    "        else:\n",
    "            torch.save(model, '../artifacts/models/street_cnn_front_right_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- running epoch 51 --\n",
      "epoch [51/100], data trained:3.154%, running avg training loss:43.1851\n",
      "-- running epoch 52 --\n",
      "epoch [52/100], data trained:3.154%, running avg training loss:35.6965\n",
      "-- running epoch 53 --\n",
      "epoch [53/100], data trained:3.154%, running avg training loss:33.3752\n",
      "-- running epoch 54 --\n",
      "epoch [54/100], data trained:3.154%, running avg training loss:34.1519\n",
      "-- running epoch 55 --\n",
      "epoch [55/100], data trained:3.154%, running avg training loss:31.8570\n",
      "-- running epoch 56 --\n",
      "epoch [56/100], data trained:3.154%, running avg training loss:30.4706\n",
      "-- running epoch 57 --\n",
      "epoch [57/100], data trained:3.154%, running avg training loss:30.9730\n",
      "-- running epoch 58 --\n",
      "epoch [58/100], data trained:3.154%, running avg training loss:29.7968\n",
      "-- running epoch 59 --\n",
      "epoch [59/100], data trained:3.154%, running avg training loss:32.5293\n",
      "-- running epoch 60 --\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-3\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "dataset_len = len(train_loader.dataset)\n",
    "val_dataset_len = len(val_loader.dataset)\n",
    "validation_losses = []\n",
    "# running_avg_training_losses = []\n",
    "\n",
    "for epoch in range(50, num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    total = 0\n",
    "    running_total_training_loss = 0\n",
    "\n",
    "    print(f'-- running epoch {epoch + 1} --')\n",
    "\n",
    "    for data in train_loader:\n",
    "        img, expected_output = data\n",
    "        img = img.to(device)\n",
    "        expected_output = expected_output.to(device)\n",
    "        expected_output = expected_output.view(expected_output.shape[0], expected_output.shape[2])\n",
    "        # ===================forward=====================\n",
    "        output = model(img) \n",
    "        loss = criterion(output, expected_output)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += 1    \n",
    "\n",
    "        running_total_training_loss += float(loss)    \n",
    "#         if len(validation_losses) == 0:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}')\n",
    "#         else:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}, validation loss (prev epoch):{validation_losses[-1]}')\n",
    "    \n",
    "    running_avg_training_losses.append(running_total_training_loss/total)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         total_vloss = 0\n",
    "#         for val_data in val_loader:\n",
    "#             vimg, v_expected_output = val_data\n",
    "#             vimg = vimg.to(device)\n",
    "#             voutput = model(vimg)\n",
    "#             vloss = criterion(voutput, v_expected_output)\n",
    "#             total_vloss += vloss\n",
    "#         validation_losses.append(total_vloss)\n",
    "\n",
    "\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, running avg training loss:{running_avg_training_losses[-1]:.4f}')\n",
    "#     print(validation_losses)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.save(model, '../artifacts/models/street_cnn_front_right_gpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(torch.device('cpu'))\n",
    "            torch.save(model, '../artifacts/models/street_cnn_front_right_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(device)   \n",
    "        else:\n",
    "            torch.save(model, '../artifacts/models/street_cnn_front_right_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
