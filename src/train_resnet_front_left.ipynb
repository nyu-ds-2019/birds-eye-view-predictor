{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "from modules.parts_top_view_AE import Autoencoder\n",
    "from modules.encodings_dataset import EncodingsDataset\n",
    "from modules.module_utils import Flatten\n",
    "from modules.module_utils import DeFlatten\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(512, 64)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "workers = 2\n",
    "\n",
    "train_dataset = EncodingsDataset(\n",
    "    '../artifacts',\n",
    "    'ae_latent_noise_gpu_model_b64_w2_e10.pt',\n",
    "    'front_left',\n",
    "    'train',\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225],\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = EncodingsDataset(\n",
    "    '../artifacts',\n",
    "    'ae_latent_noise_gpu_model_b64_w2_e10.pt',\n",
    "    'front_left',\n",
    "    'val',\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True, sampler=None)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size, shuffle=True,\n",
    "    num_workers=workers, pin_memory=True)\n",
    "\n",
    "learning_rate = 1e-1\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- running epoch 1 --\n",
      "epoch [1/50], data trained:3.154%, running avg training loss:2224.9289\n",
      "-- running epoch 2 --\n",
      "epoch [2/50], data trained:3.154%, running avg training loss:2013.5846\n",
      "-- running epoch 3 --\n",
      "epoch [3/50], data trained:3.154%, running avg training loss:1794.3666\n",
      "-- running epoch 4 --\n",
      "epoch [4/50], data trained:3.154%, running avg training loss:1593.6661\n",
      "-- running epoch 5 --\n",
      "epoch [5/50], data trained:3.154%, running avg training loss:1439.3639\n",
      "-- running epoch 6 --\n",
      "epoch [6/50], data trained:3.154%, running avg training loss:1316.1083\n",
      "-- running epoch 7 --\n",
      "epoch [7/50], data trained:3.154%, running avg training loss:1118.6056\n",
      "-- running epoch 8 --\n",
      "epoch [8/50], data trained:3.154%, running avg training loss:998.1233\n",
      "-- running epoch 9 --\n",
      "epoch [9/50], data trained:3.154%, running avg training loss:861.8722\n",
      "-- running epoch 10 --\n",
      "epoch [10/50], data trained:3.154%, running avg training loss:744.6716\n",
      "-- running epoch 11 --\n",
      "epoch [11/50], data trained:3.154%, running avg training loss:631.3540\n",
      "-- running epoch 12 --\n",
      "epoch [12/50], data trained:3.154%, running avg training loss:560.4255\n",
      "-- running epoch 13 --\n",
      "epoch [13/50], data trained:3.154%, running avg training loss:485.8668\n",
      "-- running epoch 14 --\n",
      "epoch [14/50], data trained:3.154%, running avg training loss:444.5785\n",
      "-- running epoch 15 --\n",
      "epoch [15/50], data trained:3.154%, running avg training loss:374.1437\n",
      "-- running epoch 16 --\n",
      "epoch [16/50], data trained:3.154%, running avg training loss:330.2451\n",
      "-- running epoch 17 --\n",
      "epoch [17/50], data trained:3.154%, running avg training loss:298.3261\n",
      "-- running epoch 18 --\n",
      "epoch [18/50], data trained:3.154%, running avg training loss:261.8723\n",
      "-- running epoch 19 --\n",
      "epoch [19/50], data trained:3.154%, running avg training loss:243.8677\n",
      "-- running epoch 20 --\n",
      "epoch [20/50], data trained:3.154%, running avg training loss:225.1632\n",
      "-- running epoch 21 --\n",
      "epoch [21/50], data trained:3.154%, running avg training loss:194.0884\n",
      "-- running epoch 22 --\n",
      "epoch [22/50], data trained:3.154%, running avg training loss:178.1304\n",
      "-- running epoch 23 --\n",
      "epoch [23/50], data trained:3.154%, running avg training loss:155.5093\n",
      "-- running epoch 24 --\n",
      "epoch [24/50], data trained:3.154%, running avg training loss:163.0752\n",
      "-- running epoch 25 --\n",
      "epoch [25/50], data trained:3.154%, running avg training loss:149.6147\n",
      "-- running epoch 26 --\n",
      "epoch [26/50], data trained:3.154%, running avg training loss:153.6456\n",
      "-- running epoch 27 --\n",
      "epoch [27/50], data trained:3.154%, running avg training loss:124.4675\n",
      "-- running epoch 28 --\n",
      "epoch [28/50], data trained:3.154%, running avg training loss:121.5545\n",
      "-- running epoch 29 --\n",
      "epoch [29/50], data trained:3.154%, running avg training loss:118.3153\n",
      "-- running epoch 30 --\n",
      "epoch [30/50], data trained:3.154%, running avg training loss:108.3284\n",
      "-- running epoch 31 --\n",
      "epoch [31/50], data trained:3.154%, running avg training loss:96.8734\n",
      "-- running epoch 32 --\n",
      "epoch [32/50], data trained:3.154%, running avg training loss:98.5277\n",
      "-- running epoch 33 --\n",
      "epoch [33/50], data trained:3.154%, running avg training loss:94.7477\n",
      "-- running epoch 34 --\n",
      "epoch [34/50], data trained:3.154%, running avg training loss:102.7797\n",
      "-- running epoch 35 --\n",
      "epoch [35/50], data trained:3.154%, running avg training loss:93.7924\n",
      "-- running epoch 36 --\n",
      "epoch [36/50], data trained:3.154%, running avg training loss:97.3585\n",
      "-- running epoch 37 --\n",
      "epoch [37/50], data trained:3.154%, running avg training loss:98.1781\n",
      "-- running epoch 38 --\n",
      "epoch [38/50], data trained:3.154%, running avg training loss:99.0463\n",
      "-- running epoch 39 --\n",
      "epoch [39/50], data trained:3.154%, running avg training loss:87.4466\n",
      "-- running epoch 40 --\n",
      "epoch [40/50], data trained:3.154%, running avg training loss:87.0397\n",
      "-- running epoch 41 --\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "dataset_len = len(train_loader.dataset)\n",
    "val_dataset_len = len(val_loader.dataset)\n",
    "validation_losses = []\n",
    "running_avg_training_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    total = 0\n",
    "    running_total_training_loss = 0\n",
    "\n",
    "    print(f'-- running epoch {epoch + 1} --')\n",
    "\n",
    "    for data in train_loader:\n",
    "        img, expected_output = data\n",
    "        img = img.to(device)\n",
    "        expected_output = expected_output.to(device)\n",
    "        expected_output = expected_output.view(expected_output.shape[0], expected_output.shape[2])\n",
    "        # ===================forward=====================\n",
    "        output = model(img) \n",
    "        loss = criterion(output, expected_output)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += 1    \n",
    "\n",
    "        running_total_training_loss += float(loss)    \n",
    "#         if len(validation_losses) == 0:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}')\n",
    "#         else:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}, validation loss (prev epoch):{validation_losses[-1]}')\n",
    "    \n",
    "    running_avg_training_losses.append(running_total_training_loss/total)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         total_vloss = 0\n",
    "#         for val_data in val_loader:\n",
    "#             vimg, v_expected_output = val_data\n",
    "#             vimg = vimg.to(device)\n",
    "#             voutput = model(vimg)\n",
    "#             vloss = criterion(voutput, v_expected_output)\n",
    "#             total_vloss += vloss\n",
    "#         validation_losses.append(total_vloss)\n",
    "\n",
    "\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, running avg training loss:{running_avg_training_losses[-1]:.4f}')\n",
    "#     print(validation_losses)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.save(model, '../artifacts/models/cnn_front_left_gpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(torch.device('cpu'))\n",
    "            torch.save(model, '../artifacts/models/cnn_front_left_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(device)   \n",
    "        else:\n",
    "            torch.save(model, '../artifacts/models/cnn_front_left_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- running epoch 51 --\n",
      "epoch [51/100], data trained:3.154%, running avg training loss:91.7166\n",
      "-- running epoch 52 --\n",
      "epoch [52/100], data trained:3.154%, running avg training loss:89.3718\n",
      "-- running epoch 53 --\n",
      "epoch [53/100], data trained:3.154%, running avg training loss:90.9842\n",
      "-- running epoch 54 --\n",
      "epoch [54/100], data trained:3.154%, running avg training loss:90.9537\n",
      "-- running epoch 55 --\n",
      "epoch [55/100], data trained:3.154%, running avg training loss:89.7596\n",
      "-- running epoch 56 --\n",
      "epoch [56/100], data trained:3.154%, running avg training loss:89.6707\n",
      "-- running epoch 57 --\n",
      "epoch [57/100], data trained:3.154%, running avg training loss:89.3353\n",
      "-- running epoch 58 --\n",
      "epoch [58/100], data trained:3.154%, running avg training loss:91.6757\n",
      "-- running epoch 59 --\n",
      "epoch [59/100], data trained:3.154%, running avg training loss:90.4238\n",
      "-- running epoch 60 --\n",
      "epoch [60/100], data trained:3.154%, running avg training loss:92.1738\n",
      "-- running epoch 61 --\n",
      "epoch [61/100], data trained:3.154%, running avg training loss:88.2955\n",
      "-- running epoch 62 --\n",
      "epoch [62/100], data trained:3.154%, running avg training loss:88.4621\n",
      "-- running epoch 63 --\n",
      "epoch [63/100], data trained:3.154%, running avg training loss:89.6037\n",
      "-- running epoch 64 --\n",
      "epoch [64/100], data trained:3.154%, running avg training loss:88.9777\n",
      "-- running epoch 65 --\n",
      "epoch [65/100], data trained:3.154%, running avg training loss:90.4858\n",
      "-- running epoch 66 --\n",
      "epoch [66/100], data trained:3.154%, running avg training loss:90.0903\n",
      "-- running epoch 67 --\n",
      "epoch [67/100], data trained:3.154%, running avg training loss:91.0813\n",
      "-- running epoch 68 --\n",
      "epoch [68/100], data trained:3.154%, running avg training loss:92.3779\n",
      "-- running epoch 69 --\n",
      "epoch [69/100], data trained:3.154%, running avg training loss:89.2048\n",
      "-- running epoch 70 --\n",
      "epoch [70/100], data trained:3.154%, running avg training loss:92.0538\n",
      "-- running epoch 71 --\n",
      "epoch [71/100], data trained:3.154%, running avg training loss:89.4439\n",
      "-- running epoch 72 --\n",
      "epoch [72/100], data trained:3.154%, running avg training loss:89.1592\n",
      "-- running epoch 73 --\n",
      "epoch [73/100], data trained:3.154%, running avg training loss:90.4443\n",
      "-- running epoch 74 --\n",
      "epoch [74/100], data trained:3.154%, running avg training loss:90.1972\n",
      "-- running epoch 75 --\n",
      "epoch [75/100], data trained:3.154%, running avg training loss:89.7383\n",
      "-- running epoch 76 --\n",
      "epoch [76/100], data trained:3.154%, running avg training loss:90.6488\n",
      "-- running epoch 77 --\n",
      "epoch [77/100], data trained:3.154%, running avg training loss:89.0722\n",
      "-- running epoch 78 --\n",
      "epoch [78/100], data trained:3.154%, running avg training loss:90.1588\n",
      "-- running epoch 79 --\n",
      "epoch [79/100], data trained:3.154%, running avg training loss:91.1050\n",
      "-- running epoch 80 --\n",
      "epoch [80/100], data trained:3.154%, running avg training loss:90.2995\n",
      "-- running epoch 81 --\n",
      "epoch [81/100], data trained:3.154%, running avg training loss:90.2132\n",
      "-- running epoch 82 --\n",
      "epoch [82/100], data trained:3.154%, running avg training loss:91.3228\n",
      "-- running epoch 83 --\n",
      "epoch [83/100], data trained:3.154%, running avg training loss:89.3355\n",
      "-- running epoch 84 --\n",
      "epoch [84/100], data trained:3.154%, running avg training loss:90.3012\n",
      "-- running epoch 85 --\n",
      "epoch [85/100], data trained:3.154%, running avg training loss:89.4243\n",
      "-- running epoch 86 --\n",
      "epoch [86/100], data trained:3.154%, running avg training loss:92.1493\n",
      "-- running epoch 87 --\n",
      "epoch [87/100], data trained:3.154%, running avg training loss:91.5929\n",
      "-- running epoch 88 --\n",
      "epoch [88/100], data trained:3.154%, running avg training loss:88.9358\n",
      "-- running epoch 89 --\n",
      "epoch [89/100], data trained:3.154%, running avg training loss:88.8087\n",
      "-- running epoch 90 --\n",
      "epoch [90/100], data trained:3.154%, running avg training loss:90.4434\n",
      "-- running epoch 91 --\n",
      "epoch [91/100], data trained:3.154%, running avg training loss:89.5608\n",
      "-- running epoch 92 --\n",
      "epoch [92/100], data trained:3.154%, running avg training loss:89.3991\n",
      "-- running epoch 93 --\n",
      "epoch [93/100], data trained:3.154%, running avg training loss:92.3032\n",
      "-- running epoch 94 --\n",
      "epoch [94/100], data trained:3.154%, running avg training loss:90.7067\n",
      "-- running epoch 95 --\n",
      "epoch [95/100], data trained:3.154%, running avg training loss:90.9843\n",
      "-- running epoch 96 --\n",
      "epoch [96/100], data trained:3.154%, running avg training loss:90.1911\n",
      "-- running epoch 97 --\n",
      "epoch [97/100], data trained:3.154%, running avg training loss:89.5204\n",
      "-- running epoch 98 --\n",
      "epoch [98/100], data trained:3.154%, running avg training loss:89.0339\n",
      "-- running epoch 99 --\n",
      "epoch [99/100], data trained:3.154%, running avg training loss:90.6313\n",
      "-- running epoch 100 --\n"
     ]
    }
   ],
   "source": [
    "model = torch.load('../artifacts/models/cnn_front_left_cpu_model_b64_w2_e40.pt')\n",
    "model = model.to(device)\n",
    "num_epochs = 100\n",
    "dataset_len = len(train_loader.dataset)\n",
    "val_dataset_len = len(val_loader.dataset)\n",
    "validation_losses = []\n",
    "running_avg_training_losses = []\n",
    "\n",
    "for epoch in range(50, num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    total = 0\n",
    "    running_total_training_loss = 0\n",
    "\n",
    "    print(f'-- running epoch {epoch + 1} --')\n",
    "\n",
    "    for data in train_loader:\n",
    "        img, expected_output = data\n",
    "        img = img.to(device)\n",
    "        expected_output = expected_output.to(device)\n",
    "        expected_output = expected_output.view(expected_output.shape[0], expected_output.shape[2])\n",
    "        # ===================forward=====================\n",
    "        output = model(img) \n",
    "        loss = criterion(output, expected_output)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += 1    \n",
    "\n",
    "        running_total_training_loss += float(loss)    \n",
    "#         if len(validation_losses) == 0:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}')\n",
    "#         else:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}, validation loss (prev epoch):{validation_losses[-1]}')\n",
    "    \n",
    "    running_avg_training_losses.append(running_total_training_loss/total)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         total_vloss = 0\n",
    "#         for val_data in val_loader:\n",
    "#             vimg, v_expected_output = val_data\n",
    "#             vimg = vimg.to(device)\n",
    "#             voutput = model(vimg)\n",
    "#             vloss = criterion(voutput, v_expected_output)\n",
    "#             total_vloss += vloss\n",
    "#         validation_losses.append(total_vloss)\n",
    "\n",
    "\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, running avg training loss:{running_avg_training_losses[-1]:.4f}')\n",
    "#     print(validation_losses)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.save(model, '../artifacts/models/cnn_front_left_gpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(torch.device('cpu'))\n",
    "            torch.save(model, '../artifacts/models/cnn_front_left_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(device)   \n",
    "        else:\n",
    "            torch.save(model, '../artifacts/models/cnn_front_left_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
