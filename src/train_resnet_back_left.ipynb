{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some libraries\n",
    "from modules.parts_top_view_AE import Autoencoder\n",
    "from modules.encodings_dataset import EncodingsDataset\n",
    "from modules.module_utils import Flatten\n",
    "from modules.module_utils import DeFlatten\n",
    "from torchvision import models\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18()\n",
    "model.fc = nn.Linear(512, 64)\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "\n",
    "batch_size = 32\n",
    "workers = 2\n",
    "\n",
    "train_dataset = EncodingsDataset(\n",
    "    '../artifacts',\n",
    "    'ae_latent_noise_gpu_model_b64_w2_e10.pt',\n",
    "    'back_left',\n",
    "    'train',\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225],\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "val_dataset = EncodingsDataset(\n",
    "    '../artifacts',\n",
    "    'ae_latent_noise_gpu_model_b64_w2_e10.pt',\n",
    "    'back_left',\n",
    "    'val',\n",
    "    transforms.Compose(\n",
    "        [\n",
    "            transforms.Normalize(\n",
    "                mean = [0.485, 0.456, 0.406],\n",
    "                std = [0.229, 0.224, 0.225]\n",
    "            )\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=batch_size, shuffle=True,\n",
    "        num_workers=workers, pin_memory=True, sampler=None)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size, shuffle=True,\n",
    "    num_workers=workers, pin_memory=True)\n",
    "\n",
    "learning_rate = 1e-1\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- running epoch 1 --\n",
      "epoch [1/50], data trained:3.154%, running avg training loss:2056.5392\n",
      "-- running epoch 2 --\n",
      "epoch [2/50], data trained:3.154%, running avg training loss:1851.5054\n",
      "-- running epoch 3 --\n",
      "epoch [3/50], data trained:3.154%, running avg training loss:1690.4338\n",
      "-- running epoch 4 --\n",
      "epoch [4/50], data trained:3.154%, running avg training loss:1548.8420\n",
      "-- running epoch 5 --\n",
      "epoch [5/50], data trained:3.154%, running avg training loss:1442.9788\n",
      "-- running epoch 6 --\n",
      "epoch [6/50], data trained:3.154%, running avg training loss:1321.8312\n",
      "-- running epoch 7 --\n",
      "epoch [7/50], data trained:3.154%, running avg training loss:1204.8600\n",
      "-- running epoch 8 --\n",
      "epoch [8/50], data trained:3.154%, running avg training loss:1120.8279\n",
      "-- running epoch 9 --\n",
      "epoch [9/50], data trained:3.154%, running avg training loss:987.4314\n",
      "-- running epoch 10 --\n",
      "epoch [10/50], data trained:3.154%, running avg training loss:885.9451\n",
      "-- running epoch 11 --\n",
      "epoch [11/50], data trained:3.154%, running avg training loss:780.4370\n",
      "-- running epoch 12 --\n",
      "epoch [12/50], data trained:3.154%, running avg training loss:684.2546\n",
      "-- running epoch 13 --\n",
      "epoch [13/50], data trained:3.154%, running avg training loss:626.6665\n",
      "-- running epoch 14 --\n",
      "epoch [14/50], data trained:3.154%, running avg training loss:524.3247\n",
      "-- running epoch 15 --\n",
      "epoch [15/50], data trained:3.154%, running avg training loss:475.5964\n",
      "-- running epoch 16 --\n",
      "epoch [16/50], data trained:3.154%, running avg training loss:431.6136\n",
      "-- running epoch 17 --\n",
      "epoch [17/50], data trained:3.154%, running avg training loss:385.9930\n",
      "-- running epoch 18 --\n",
      "epoch [18/50], data trained:3.154%, running avg training loss:359.6744\n",
      "-- running epoch 19 --\n",
      "epoch [19/50], data trained:3.154%, running avg training loss:313.9957\n",
      "-- running epoch 20 --\n",
      "epoch [20/50], data trained:3.154%, running avg training loss:282.3678\n",
      "-- running epoch 21 --\n",
      "epoch [21/50], data trained:3.154%, running avg training loss:255.0706\n",
      "-- running epoch 22 --\n",
      "epoch [22/50], data trained:3.154%, running avg training loss:247.5421\n",
      "-- running epoch 23 --\n",
      "epoch [23/50], data trained:3.154%, running avg training loss:217.5370\n",
      "-- running epoch 24 --\n",
      "epoch [24/50], data trained:3.154%, running avg training loss:189.6495\n",
      "-- running epoch 25 --\n",
      "epoch [25/50], data trained:3.154%, running avg training loss:178.9908\n",
      "-- running epoch 26 --\n",
      "epoch [26/50], data trained:3.154%, running avg training loss:166.2648\n",
      "-- running epoch 27 --\n",
      "epoch [27/50], data trained:3.154%, running avg training loss:155.6767\n",
      "-- running epoch 28 --\n",
      "epoch [28/50], data trained:3.154%, running avg training loss:149.2939\n",
      "-- running epoch 29 --\n",
      "epoch [29/50], data trained:3.154%, running avg training loss:133.3544\n",
      "-- running epoch 30 --\n",
      "epoch [30/50], data trained:3.154%, running avg training loss:124.5776\n",
      "-- running epoch 31 --\n",
      "epoch [31/50], data trained:3.154%, running avg training loss:135.2544\n",
      "-- running epoch 32 --\n",
      "epoch [32/50], data trained:3.154%, running avg training loss:121.2498\n",
      "-- running epoch 33 --\n",
      "epoch [33/50], data trained:3.154%, running avg training loss:110.2354\n",
      "-- running epoch 34 --\n",
      "epoch [34/50], data trained:3.154%, running avg training loss:103.5573\n",
      "-- running epoch 35 --\n",
      "epoch [35/50], data trained:3.154%, running avg training loss:101.1459\n",
      "-- running epoch 36 --\n",
      "epoch [36/50], data trained:3.154%, running avg training loss:101.0281\n",
      "-- running epoch 37 --\n",
      "epoch [37/50], data trained:3.154%, running avg training loss:101.5924\n",
      "-- running epoch 38 --\n",
      "epoch [38/50], data trained:3.154%, running avg training loss:95.0644\n",
      "-- running epoch 39 --\n",
      "epoch [39/50], data trained:3.154%, running avg training loss:88.2536\n",
      "-- running epoch 40 --\n",
      "epoch [40/50], data trained:3.154%, running avg training loss:108.3536\n",
      "-- running epoch 41 --\n",
      "epoch [41/50], data trained:3.154%, running avg training loss:86.5524\n",
      "-- running epoch 42 --\n",
      "epoch [42/50], data trained:3.154%, running avg training loss:72.8258\n",
      "-- running epoch 43 --\n",
      "epoch [43/50], data trained:3.154%, running avg training loss:76.9292\n",
      "-- running epoch 44 --\n",
      "epoch [44/50], data trained:3.154%, running avg training loss:73.2735\n",
      "-- running epoch 45 --\n",
      "epoch [45/50], data trained:3.154%, running avg training loss:74.2322\n",
      "-- running epoch 46 --\n",
      "epoch [46/50], data trained:3.154%, running avg training loss:69.9552\n",
      "-- running epoch 47 --\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-57376752c95b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'-- running epoch {epoch + 1} --'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    839\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    840\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 841\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    842\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    843\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    796\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 798\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    799\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    800\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/queue.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    177\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m             \u001b[0mitem\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnot_full\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/pytorch/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 300\u001b[0;31m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    301\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "dataset_len = len(train_loader.dataset)\n",
    "val_dataset_len = len(val_loader.dataset)\n",
    "validation_losses = []\n",
    "running_avg_training_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    total = 0\n",
    "    running_total_training_loss = 0\n",
    "\n",
    "    print(f'-- running epoch {epoch + 1} --')\n",
    "\n",
    "    for data in train_loader:\n",
    "        img, expected_output = data\n",
    "        img = img.to(device)\n",
    "        expected_output = expected_output.to(device)\n",
    "        expected_output = expected_output.view(expected_output.shape[0], expected_output.shape[2])\n",
    "        # ===================forward=====================\n",
    "        output = model(img) \n",
    "        loss = criterion(output, expected_output)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += 1    \n",
    "\n",
    "        running_total_training_loss += float(loss)    \n",
    "#         if len(validation_losses) == 0:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}')\n",
    "#         else:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}, validation loss (prev epoch):{validation_losses[-1]}')\n",
    "    \n",
    "    running_avg_training_losses.append(running_total_training_loss/total)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         total_vloss = 0\n",
    "#         for val_data in val_loader:\n",
    "#             vimg, v_expected_output = val_data\n",
    "#             vimg = vimg.to(device)\n",
    "#             voutput = model(vimg)\n",
    "#             vloss = criterion(voutput, v_expected_output)\n",
    "#             total_vloss += vloss\n",
    "#         validation_losses.append(total_vloss)\n",
    "\n",
    "\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, running avg training loss:{running_avg_training_losses[-1]:.4f}')\n",
    "#     print(validation_losses)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.save(model, '../artifacts/models/street_cnn_back_left_gpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(torch.device('cpu'))\n",
    "            torch.save(model, '../artifacts/models/street_cnn_back_left_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(device)   \n",
    "        else:\n",
    "            torch.save(model, '../artifacts/models/street_cnn_back_left_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- running epoch 71 --\n",
      "epoch [71/100], data trained:3.154%, running avg training loss:43.0575\n",
      "-- running epoch 72 --\n",
      "epoch [72/100], data trained:3.154%, running avg training loss:43.5333\n",
      "-- running epoch 73 --\n",
      "epoch [73/100], data trained:3.154%, running avg training loss:45.0113\n",
      "-- running epoch 74 --\n",
      "epoch [74/100], data trained:3.154%, running avg training loss:42.9910\n",
      "-- running epoch 75 --\n",
      "epoch [75/100], data trained:3.154%, running avg training loss:43.1563\n",
      "-- running epoch 76 --\n",
      "epoch [76/100], data trained:3.154%, running avg training loss:44.3712\n",
      "-- running epoch 77 --\n",
      "epoch [77/100], data trained:3.154%, running avg training loss:43.4416\n",
      "-- running epoch 78 --\n",
      "epoch [78/100], data trained:3.154%, running avg training loss:43.6968\n",
      "-- running epoch 79 --\n",
      "epoch [79/100], data trained:3.154%, running avg training loss:44.2042\n",
      "-- running epoch 80 --\n",
      "epoch [80/100], data trained:3.154%, running avg training loss:43.4366\n",
      "-- running epoch 81 --\n",
      "epoch [81/100], data trained:3.154%, running avg training loss:43.8717\n",
      "-- running epoch 82 --\n",
      "epoch [82/100], data trained:3.154%, running avg training loss:42.7802\n",
      "-- running epoch 83 --\n",
      "epoch [83/100], data trained:3.154%, running avg training loss:42.4704\n",
      "-- running epoch 84 --\n",
      "epoch [84/100], data trained:3.154%, running avg training loss:44.8553\n",
      "-- running epoch 85 --\n",
      "epoch [85/100], data trained:3.154%, running avg training loss:43.0899\n",
      "-- running epoch 86 --\n",
      "epoch [86/100], data trained:3.154%, running avg training loss:41.9882\n",
      "-- running epoch 87 --\n",
      "epoch [87/100], data trained:3.154%, running avg training loss:43.1022\n",
      "-- running epoch 88 --\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-5\n",
    "\n",
    "optimizer = torch.optim.Adam(\n",
    "    model.parameters(),\n",
    "    lr=learning_rate,\n",
    ")\n",
    "\n",
    "\n",
    "model = torch.load('../artifacts/models/street_cnn_back_left_gpu_model_b64_w2_e70.pt')\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "num_epochs = 100\n",
    "dataset_len = len(train_loader.dataset)\n",
    "val_dataset_len = len(val_loader.dataset)\n",
    "validation_losses = []\n",
    "running_avg_training_losses = []\n",
    "\n",
    "for epoch in range(70, num_epochs):\n",
    "    torch.cuda.empty_cache()\n",
    "    total = 0\n",
    "    running_total_training_loss = 0\n",
    "\n",
    "    print(f'-- running epoch {epoch + 1} --')\n",
    "\n",
    "    for data in train_loader:\n",
    "        img, expected_output = data\n",
    "        img = img.to(device)\n",
    "        expected_output = expected_output.to(device)\n",
    "        expected_output = expected_output.view(expected_output.shape[0], expected_output.shape[2])\n",
    "        # ===================forward=====================\n",
    "        output = model(img) \n",
    "        loss = criterion(output, expected_output)\n",
    "        # ===================backward====================\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total += 1    \n",
    "\n",
    "        running_total_training_loss += float(loss)    \n",
    "#         if len(validation_losses) == 0:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}')\n",
    "#         else:\n",
    "#             print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, training loss:{loss.item():.4f}, validation loss (prev epoch):{validation_losses[-1]}')\n",
    "    \n",
    "    running_avg_training_losses.append(running_total_training_loss/total)\n",
    "\n",
    "#     with torch.no_grad():\n",
    "#         total_vloss = 0\n",
    "#         for val_data in val_loader:\n",
    "#             vimg, v_expected_output = val_data\n",
    "#             vimg = vimg.to(device)\n",
    "#             voutput = model(vimg)\n",
    "#             vloss = criterion(voutput, v_expected_output)\n",
    "#             total_vloss += vloss\n",
    "#         validation_losses.append(total_vloss)\n",
    "\n",
    "\n",
    "    print(f'epoch [{epoch + 1}/{num_epochs}], data trained:{100 * total / dataset_len :.3f}%, running avg training loss:{running_avg_training_losses[-1]:.4f}')\n",
    "#     print(validation_losses)\n",
    "\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        if torch.cuda.is_available():\n",
    "            torch.save(model, '../artifacts/models/street_cnn_back_left_gpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(torch.device('cpu'))\n",
    "            torch.save(model, '../artifacts/models/street_cnn_back_left_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')\n",
    "            model.to(device)   \n",
    "        else:\n",
    "            torch.save(model, '../artifacts/models/street_cnn_back_left_cpu_model_b64_w2_e'+ str(epoch + 1) +'.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
